{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, GRU\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[70, 746, 825, 109, 2083, 0, 2, 0, 0, 0, 9, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1209, 179, 1952, 4, 4959, 7, 0, 2, 978, 1522,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[287, 3, 3330, 0, 23, 12, 13, 465, 74, 8, 0, 8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 3, 592, 19, 2, 706, 1439, 2575, 7, 2, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[9, 2, 110, 12, 42, 32, 44, 361, 9, 3860, 2358...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34395</th>\n",
       "      <td>[175, 1317, 38, 754, 9, 5, 0, 228, 1, 45, 6, 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34396</th>\n",
       "      <td>[466, 5, 70, 1242, 6, 3888, 1, 34, 43, 5, 70, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34397</th>\n",
       "      <td>[10, 0, 21, 1650, 18, 5, 1335, 1, 208, 5, 997,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34398</th>\n",
       "      <td>[18, 39, 316, 133, 365, 2019, 1, 27, 10, 5, 61...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34399</th>\n",
       "      <td>[10, 0, 859, 36, 860, 765, 250, 1, 872, 3, 27,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34400 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      [70, 746, 825, 109, 2083, 0, 2, 0, 0, 0, 9, 0,...      1\n",
       "1      [1209, 179, 1952, 4, 4959, 7, 0, 2, 978, 1522,...      1\n",
       "2      [287, 3, 3330, 0, 23, 12, 13, 465, 74, 8, 0, 8...      1\n",
       "3      [0, 0, 3, 592, 19, 2, 706, 1439, 2575, 7, 2, 0...      1\n",
       "4      [9, 2, 110, 12, 42, 32, 44, 361, 9, 3860, 2358...      1\n",
       "...                                                  ...    ...\n",
       "34395  [175, 1317, 38, 754, 9, 5, 0, 228, 1, 45, 6, 2...      0\n",
       "34396  [466, 5, 70, 1242, 6, 3888, 1, 34, 43, 5, 70, ...      0\n",
       "34397  [10, 0, 21, 1650, 18, 5, 1335, 1, 208, 5, 997,...      0\n",
       "34398  [18, 39, 316, 133, 365, 2019, 1, 27, 10, 5, 61...      0\n",
       "34399  [10, 0, 859, 36, 860, 765, 250, 1, 872, 3, 27,...      0\n",
       "\n",
       "[34400 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_1 = 'data/domain1_train.json'\n",
    "df1 = pd.read_json(file_path_1, lines=True)\n",
    "\n",
    "\n",
    "file_path_2 = 'data/domain2_train.json'\n",
    "df2 = pd.read_json(file_path_2, lines=True).drop('model', axis=1)\n",
    "\n",
    "\n",
    "df_comb = pd.concat([df1, df2],axis=0,ignore_index=True)\n",
    "\n",
    "df_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 48, 124, 23, 63, 637, 1, 682, 62]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_comb['text'])\n",
    "y = np.array(df_comb['label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train[27519]) \n",
    "print(y_train[27519])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average length of each sentence is 90.3398546511628\n",
      "The max length of the sentences is 1075\n",
      "The min length of the sentence is 0\n",
      "The median is 44.0\n",
      "The 75th percentile is 114.0\n",
      "The 25th percentile is 26.0\n"
     ]
    }
   ],
   "source": [
    "len_lis = [len(x) for x in X]\n",
    "print(f\"The average length of each sentence is {np.mean(len_lis)}\")\n",
    "print(f\"The max length of the sentences is {np.max(len_lis)}\")\n",
    "print(f\"The min length of the sentence is {np.min(len_lis)}\")\n",
    "print(f\"The median is {np.median(len_lis)}\")\n",
    "print(f\"The 75th percentile is {np.percentile(len_lis, 75)}\")\n",
    "print(f\"The 25th percentile is {np.percentile(len_lis, 25)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "num_classes = 2\n",
    "\n",
    "# Hyperparameters\n",
    "maxlen = 80  #Start with the median, max at 75th percentile\n",
    "batch_size = 32 # base on experiment 32 is reasonable starting point (the best)\n",
    "n_epochs = 20\n",
    "# recommened learning rate is 0.001 to 0.005. usually 0.002 and 0.003 is the best\n",
    "learning_rate = 0.002\n",
    "# start small and increase gradually \n",
    "hidden_layers = 32\n",
    "early_stop_patience = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0 1225    7    0    0 1813 3042   38   24 3887   90    5    0    6\n",
      " 3059  953    3    0    2    0    9 1080    7 3708    9   73   34  405\n",
      "    0 2129    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "print(X_train[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27520, 2)\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27520, 80, 1)\n",
      "(6880, 80, 1)\n"
     ]
    }
   ],
   "source": [
    "#(samples, timesteps, features)\n",
    "#(batch_size, timesteps, input_dim)\n",
    "X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "print(X_train.shape)  #(750, 100, 1)\n",
    "\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_rnn():\n",
    "    model = Sequential()\n",
    "    model.add(GRU(hidden_layers, input_shape = (maxlen,1), return_sequences = False))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate = learning_rate)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy\\AppData\\Local\\Temp\\ipykernel_29020\\1728091606.py:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = vanilla_rnn, epochs = n_epochs, batch_size = batch_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_8 (GRU)                 (None, 32)                3360      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,426\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "860/860 [==============================] - 11s 11ms/step - loss: 0.5094 - accuracy: 0.7449\n",
      "Epoch 2/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3931 - accuracy: 0.8465\n",
      "Epoch 3/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3757 - accuracy: 0.8568\n",
      "Epoch 4/20\n",
      "860/860 [==============================] - 10s 12ms/step - loss: 0.3647 - accuracy: 0.8615\n",
      "Epoch 5/20\n",
      "860/860 [==============================] - 10s 12ms/step - loss: 0.3587 - accuracy: 0.8642\n",
      "Epoch 6/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3526 - accuracy: 0.8671\n",
      "Epoch 7/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3483 - accuracy: 0.8685\n",
      "Epoch 8/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3421 - accuracy: 0.8701\n",
      "Epoch 9/20\n",
      "860/860 [==============================] - 10s 12ms/step - loss: 0.3393 - accuracy: 0.8711\n",
      "Epoch 10/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3383 - accuracy: 0.8715\n",
      "Epoch 11/20\n",
      "860/860 [==============================] - 9s 10ms/step - loss: 0.3318 - accuracy: 0.8740\n",
      "Epoch 12/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3286 - accuracy: 0.8758\n",
      "Epoch 13/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3255 - accuracy: 0.8766\n",
      "Epoch 14/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3302 - accuracy: 0.8739\n",
      "Epoch 15/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3213 - accuracy: 0.8776\n",
      "Epoch 16/20\n",
      "860/860 [==============================] - 9s 11ms/step - loss: 0.3200 - accuracy: 0.8786\n",
      "Epoch 17/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3193 - accuracy: 0.8789\n",
      "Epoch 18/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3193 - accuracy: 0.8786\n",
      "Epoch 19/20\n",
      "860/860 [==============================] - 10s 11ms/step - loss: 0.3208 - accuracy: 0.8779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f92554040>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopping = callbacks.EarlyStopping(monitor=\"accuracy\",\n",
    "                                        mode=\"max\", patience=early_stop_patience,\n",
    "                                        restore_best_weights=True)\n",
    "model = KerasClassifier(build_fn = vanilla_rnn, epochs = n_epochs, batch_size = batch_size)\n",
    "model.fit(X_train, y_train, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 1s 6ms/step\n",
      "0.8738372093023256\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_test_ = np.argmax(y_test, axis = 1)\n",
    "\n",
    "print(accuracy_score(y_pred, y_test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "file_path_test = 'data/test_set.json'\n",
    "df_test = pd.read_json(file_path_test, lines=True)\n",
    "X_Kaggle = np.array(df_test['text'])\n",
    "X_Kaggle = pad_sequences(X_Kaggle, padding='post', maxlen=maxlen)\n",
    "X_Kaggle = np.array(X_Kaggle).reshape((X_Kaggle.shape[0], X_Kaggle.shape[1], 1))\n",
    "y_Kaggle = model.predict(X_Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add predictions to the test DataFrame\n",
    "df_test['class'] = y_Kaggle\n",
    "\n",
    "# # Select only the columns you want to include in the CSV\n",
    "selected_columns = ['id', 'class']  # Include other columns as needed\n",
    "\n",
    "# # Save the selected columns to a CSV file\n",
    "df_test[selected_columns].to_csv('prediction/GRU_RNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average length of each sentence is 110.615\n",
      "The max length of the sentences is 933\n",
      "The min length of the sentence is 4\n",
      "The median is 48.0\n",
      "The 75th percentile is 148.0\n",
      "The 25th percentile is 28.0\n"
     ]
    }
   ],
   "source": [
    "file_path_test = 'data/test_set.json'\n",
    "df_test = pd.read_json(file_path_test, lines=True)\n",
    "X_Kaggle = np.array(df_test['text'])\n",
    "len_lis = [len(x) for x in X_Kaggle]\n",
    "print(f\"The average length of each sentence is {np.mean(len_lis)}\")\n",
    "print(f\"The max length of the sentences is {np.max(len_lis)}\")\n",
    "print(f\"The min length of the sentence is {np.min(len_lis)}\")\n",
    "print(f\"The median is {np.median(len_lis)}\")\n",
    "print(f\"The 75th percentile is {np.percentile(len_lis, 75)}\")\n",
    "print(f\"The 25th percentile is {np.percentile(len_lis, 25)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
